ts=2025-11-25T02:56:08.905717152Z level=info msg="finished node evaluation" controller_path=/ controller_id="" trace_id=bccd2df622b2bae96c8a714dfacbdc1b node_id=loki.source.kubernetes.pods duration=1.231359ms
ts=2025-11-25T02:56:08.906727892Z level=info msg="finished node evaluation" controller_path=/ controller_id="" trace_id=bccd2df622b2bae96c8a714dfacbdc1b node_id=pyroscope.write.local duration=973.689µs
ts=2025-11-25T02:56:08.999538714Z level=info msg="using embedded asprof dist" component_path=/ component_id=pyroscope.java.java
ts=2025-11-25T02:56:08.999863031Z level=info msg="finished node evaluation" controller_path=/ controller_id="" trace_id=bccd2df622b2bae96c8a714dfacbdc1b node_id=pyroscope.java.java duration=93.091461ms
ts=2025-11-25T02:56:09.000048868Z level=info msg="finished node evaluation" controller_path=/ controller_id="" trace_id=bccd2df622b2bae96c8a714dfacbdc1b node_id=otel duration=75.603µs
ts=2025-11-25T02:56:09.000133993Z level=info msg="finished complete graph evaluation" controller_path=/ controller_id="" trace_id=bccd2df622b2bae96c8a714dfacbdc1b duration=103.475323ms
Error: /etc/alloy/config.alloy:22:3: unrecognized attribute name "host_root"

21 |   // join = discovery.kubernetes.pods.targets
22 |   host_root = "/hostfs"
   |   ^^^^^^^^^^^^^^^^^^^^^
23 | }

interrupt received

  # -- Security context to apply to the Grafana Alloy pod.
  podSecurityContext:
    privileged: true
    runAsUser: 0
    capabilities:
      add: ["SYS_ADMIN", "SYS_PTRACE"]

W1125 03:06:01.724749 2700418 warnings.go:70] unknown field "spec.template.spec.securityContext.capabilities"
W1125 03:06:01.724793 2700418 warnings.go:70] unknown field "spec.template.spec.securityContext.privileged"
Release "alloy" has been upgraded. Happy Helming!
NAME: alloy
LAST DEPLOYED: Tue Nov 25 03:06:00 2025
NAMESPACE: test-molo
STATUS: deployed
REVISION: 3
TEST SUITE: None
NOTES:
Welcome to Grafana Alloy!
Error: /etc/alloy/config.alloy:22:3: unrecognized attribute name "host_root"

21 |   //join = discovery.kubernetes.pods.targets
22 |   host_root = "/hostfs"
   |   ^^^^^^^^^^^^^^^^^^^^^
23 |   join = discovery.kubernetes.pods.targets

Error: could not perform the initial load successfully


: 2025-11-18T01:01:08Z, oldest acceptable timestamp is: 2025-11-18T03:16:01Z; 1 errors like: entry for stream '{instance=\"rook-ceph/rook-ceph-exporter-stg-master01-7bf597c4b9-7xcw2:ceph-exporter\", job=\"loki.source.kubernetes.pods\", service_name=\"loki.source.kubernetes.pods\"}' has timestamp too old: 2025-11-18T01:02:23Z, oldest acceptable timestamp is: 2025-11-18T03:16:01Z; 1 errors like: entry for stream '{instance=\"rook-ceph/rook-ceph-exporter-stg-master01-7bf597c4b9-7xcw2:ceph-exporter\", job=\"loki.s"
ts=2025-11-25T03:16:09.570771486Z level=error msg="final error sending batch, no retries left, dropping data" component_path=/ component_id=loki.write.endpoint component=client host=loki:3100 status=400 tenant=local error="server returned HTTP status 400 Bad Request (400): 1 errors like: entry for stream '{instance=\"rook-ceph/rook-ceph-exporter-stg-master01-7bf597c4b9-7xcw2:ceph-exporter\", job=\"loki.source.kubernetes.pods\", service_name=\"loki.source.kubernetes.pods\"}' has timestamp too old: 2025-11-18T02:00:12Z, oldest acceptable timestamp is: 2025-11-18T03:16:02Z; 1 errors like: entry for stream '{instance=\"rook-ceph/rook-ceph-exporter-stg-master01-7bf597c4b9-7xcw2:ceph-exporter\", job=\"loki.source.kubernetes.pods\", service_name=\"loki.source.kubernetes.pods\"}' has timestamp too old: 2025-11-18T02:10:29Z, oldest acceptable timestamp is: 2025-11-18T03:16:02Z; 1 errors like: entry for stream '{instance=\"rook-ceph/rook-ceph-exporter-stg-master01-7bf597c4b9-7xcw2:ceph-exporter\", job=\"loki.source.kubernetes.pods\", service_name=\"loki.source.kubernetes.pods\"}' has timestamp too old: 2025-11-18T02:22:27Z, oldest acceptable timestamp is: 2025-11-18T03:16:02Z; 1 errors like: entry for stream '{instance=\"rook-ceph/rook-ceph-exporter-stg-master01-7bf597c4b9-7xcw2:ceph-exporter\", job=\"loki.s"


Error: /etc/alloy/config.alloy:129:13: expected block label, got TERMINATOR

128 |       protocols {
129 |         grpc
    |             
130 |         http

Error: /etc/alloy/config.alloy:130:9: expected attribute assignment or block body, got IDENT

129 |         grpc
130 |         http
    |         ^
131 |       }

Error: /etc/alloy/config.alloy:164:2: expected }, got EOF

163 |   }
164 | }
    |  
interrupt received
Error: could not perform the initial load successfully


Error: /etc/alloy/config.alloy:124:1: cannot find the definition of component name "otelcol.exporter.tempo"

123 | 
124 | otelcol.exporter.tempo "tempo" {
    | ^^^^^^^^^^^^^^^^^^^^^^
125 |   endpoint = "http://tempo:4317"

Error: /etc/alloy/config.alloy:136:1: cannot find the definition of component name "otelcol.service"

135 | 
136 | otelcol.service "default" {
    | ^^^^^^^^^^^^^^^
137 |   pipelines {

interrupt received
Error: could not perform the initial load successfully


a@stg-master01:~/app-main/appapp-appyaml/alloy$ kl  alloy-khbzv

Error: /etc/alloy/config.alloy:158:1: cannot find the definition of component name "otelcol.service"

157 | 
158 | otelcol.service "default" {
    | ^^^^^^^^^^^^^^^
159 |   pipelines {
Error: could not perform the initial load successfully

[otel.javaagent 2025-11-25 17:54:53:151 +0700] [OkHttp http://alloy.test-molo.svc.cluster.local:12345/...] WARN io.opentelemetry.exporter.internal.grpc.GrpcExporter - Failed to export spans. Server responded with gRPC status code 2. Error message: 
[otel.javaagent 2025-11-25 17:54:58:176 +0700] [OkHttp http://alloy.test-molo.svc.cluster.local:12345/...] WARN io.opentelemetry.exporter.internal.grpc.GrpcExporter - Failed to export spans. Server responded with gRPC status code 2. Error message: 

ting to start: trying and failing to pull image"
ts=2025-11-26T11:42:27.929410369Z level=info msg="Done replaying WAL" component_path=/ component_id=prometheus.remote_write.endpoint subcomponent=rw remote_name=363939 url=http://prometheus-kube-prometheus-prometheus:9090/api/v1/push duration=45.364772274s
ts=2025-11-26T11:42:32.611276284Z level=error msg="non-recoverable error" component_path=/ component_id=prometheus.remote_write.endpoint subcomponent=rw remote_name=363939 url=http://prometheus-kube-prometheus-prometheus:9090/api/v1/push failedSampleCount=1 failedHistogramCount=0 failedExemplarCount=4 err="server returned HTTP status 404 Not Found: 404 page not found\n"
ts=2025-11-26T11:42:41.389958271Z level=warn msg="tailer stopped; will retry" target=molo/monitor-node-exporter-vjdrx:node-exporter component_path=/ component_id=loki.source.kubernetes.pods err="container \"node-exporter\" in pod \"monitor-node-exporter-vjdrx\" is waiting to start: trying and failing to pull image"
ts=2025-11-26T11:43:24.497328698Z level=warn msg="tailer stopped; will retry" target=molo/monitor-node-exporter-vjdrx:node-exporter component_path=/ component_id=loki.source.kubernetes.pods err="container \"node-exporter\" in pod \"monitor-node-exporter-vjdrx\" is waiting to start: trying and failing to pull image"
ts=2025-11-26T11:43:32.843744678Z level=error msg="non-recoverable error" component_path=/ component_id=prometheus.remote_write.endpoint subcomponent=rw remote_name=363939 url=http://prometheus-kube-prometheus-prometheus:9090/api/v1/push failedSampleCount=166 failedHistogramCount=0 failedExemplarCount=2 err="server returned HTTP status 404 Not Found: 404 page not found\n"
ts=2025-11-26T11:44:24.463402278Z level=warn msg="tailer stopped; will retry" target=molo/monitor-node-exporter-vjdrx:node-exporter component_path=/ component_id=loki.source.kubernetes.pods err="container \"node-exporter\" in pod \"monitor-node-exporter-vjdrx\" is waiting to start: trying and failing to pull image"
ts=2025-11-26T11:44:42.449918719Z level=info msg="reload requested via /-/reload endpoint" service=http

I have no name!@svim-53-208:~/.vnc$ vncserver -localhost :1
xauth: (stdin):1:  bad display name "svim-53-208:7" in "add" command

New 'svim-53-208:7 (scloud)' desktop is svim-53-208:7

Starting applications specified in /home/scloud/.vnc/xstartup
Log file is /home/scloud/.vnc/svim-53-208:7.log

I have no name!@svim-53-208:~/.vnc$ cat /home/scloud/.vnc/svim-53-208:7.log

Fatal server error:
Server is already active for display 1
        If this server is no longer running, remove /tmp/.X1-lock
        and start again.

xrdb: Connection refused
xrdb: Can't open display 'svim-53-208:7'
xsetroot:  unable to open display 'svim-53-208:7'


I have no name!@svim-53-208:~/.vnc$ vncserver -kill :1

Can't find file /home/scloud/.vnc/svim-53-208:1.pid
You'll have to kill the Xvnc4 process manually

I have no name!@svim-53-208:~/.vnc$ vncserver -kill :7

Can't find file /home/scloud/.vnc/svim-53-208:7.pid
You'll have to kill the Xvnc4 process manually

I have no name!@svim-53-208:~/.vnc$ vncserver :1
A VNC server is already running as :1
